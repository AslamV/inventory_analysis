{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e1f1ae8-757c-4d16-b4c2-9c53e9e77960",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Table Orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00a08e9a-d775-4182-945a-8baad6f041ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "unit = dbutils.widgets.get(\"unit\")\n",
    "tb_type = dbutils.widgets.get(\"tb_type\")\n",
    "print(unit)\n",
    "print(tb_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "831336be-12af-4581-92d9-d18874fde4ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from datetime import datetime\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e23eb2ed-dfa3-457d-b846-219541fe06dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fileLookup = spark.read.table('inventory_project.metadata.filelookup')\\\n",
    "    .filter((col(\"schema\") == \"gold\") & (col(\"description\").startswith(unit)) & (col(\"description\").contains(tb_type)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "683c2233-bd98-4e91-a285-e54d0a6dcb31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def updateFileLookup(table_name, status):\n",
    "    # Filter only the specific table row\n",
    "    df = fileLookup.filter(col(\"table_name\") == table_name) \\\n",
    "                   .withColumn(\"lastRunStatus\", lit(status)) \\\n",
    "                   .withColumn(\"lastUpdatetime\", current_timestamp())\n",
    "    \n",
    "    target_table = DeltaTable.forName(spark, \"inventory_project.metadata.filelookup\")\n",
    "\n",
    "    # Perform merge (upsert)\n",
    "    target_table.alias(\"t\") \\\n",
    "        .merge(\n",
    "            df.alias(\"s\"),\n",
    "            \"t.table_name = s.table_name\"\n",
    "        ) \\\n",
    "        .whenMatchedUpdate(set={              \n",
    "            \"lastRunStatus\": \"s.lastRunStatus\",\n",
    "            \"lastUpdatetime\": \"s.lastUpdatetime\"\n",
    "        }) \\\n",
    "        .whenNotMatchedInsertAll() \\\n",
    "        .execute()\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84ed4949-32e8-44a0-9c82-2217bc335683",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_notebook(row):\n",
    "    status = 'success'\n",
    "    error = 'Nil'\n",
    "    start_time = datetime.now()\n",
    "    user = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "    name = row['table_name']\n",
    "    path = row['source_path']\n",
    "    try:\n",
    "        print(f\"Processing notebook {name}\")\n",
    "        dbutils.notebook.run(path,600,{\"name\":name})\n",
    "    except Exception as e:\n",
    "        status = 'fail'\n",
    "        error = str(e)\n",
    "        print(f\"Error processing notebook {name}: {e}\")\n",
    "        raise e\n",
    "    finally:\n",
    "        end_time = datetime.now()\n",
    "        print(f\"Notebook {name} took {end_time-start_time} seconds to run\")\n",
    "        updateFileLookup(name,status)\n",
    "        audit_rows.append(Row(table_name = name, \n",
    "                              start_time = start_time, \n",
    "                              end_time = end_time, \n",
    "                              duration = str((end_time-start_time).total_seconds()), \n",
    "                              status = status,\n",
    "                              error_message = error,\n",
    "                              created_by = user,\n",
    "                              created_date = datetime.now()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2cb03e4-6d51-4a20-964b-50fcbe4082c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "audit_rows = []\n",
    "for row in fileLookup.collect():\n",
    "    process_notebook(row)\n",
    "if audit_rows:   # only if list is not empty\n",
    "    audit_df = spark.createDataFrame(audit_rows)\n",
    "    audit_df.write \\\n",
    "        .format(\"delta\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .saveAsTable(\"inventory_project.metadata.audit_log\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "dim_table_orchestrator",
   "widgets": {
    "tb_type": {
     "currentValue": "dim",
     "nuid": "d6cfc1a3-56ce-46ff-a25b-e0ca094ecabf",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "dim",
      "label": null,
      "name": "tb_type",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "dim",
      "label": null,
      "name": "tb_type",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "unit": {
     "currentValue": "ERP",
     "nuid": "7dc1d277-4e20-40bc-9172-4088677274d1",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "ERP",
      "label": null,
      "name": "unit",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "ERP",
      "label": null,
      "name": "unit",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
