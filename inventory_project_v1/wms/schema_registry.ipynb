{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "572b8fe4-29d7-4a5c-9c54-26c1bbbbe9e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import * \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3e4309c-c56a-42e1-b741-ed9ea7a5c9da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE TABLE IF NOT EXISTS inventory_project.metadata.schema_registry (\n",
    "    source STRING,\n",
    "    schema_version INT,\n",
    "    schema_json STRING,        -- store as JSON string\n",
    "    effective_from TIMESTAMP,\n",
    "    status STRING              -- e.g., 'active', 'deprecated'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cff5f53-a047-42b1-b4cb-616cc56c9baf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def publish_schema(source_name):\n",
    "  bronze_df = spark.read.table(f\"inventory_project.bronze.{source_name}\")\n",
    "  current_schema = bronze_df.schema.json()\n",
    "  try:\n",
    "    latest_schema_row = (spark.table(\"inventory_project.metadata.schema_registry\")\n",
    "                              .filter(col(\"source\") == source_name)\n",
    "                              .orderBy(col(\"schema_version\").desc())\n",
    "                              .first())\n",
    "    latest_schema = latest_schema_row['schema_json'] if latest_schema_row else None\n",
    "    latest_version = latest_schema_row['schema_version'] if latest_schema_row else 0\n",
    "  except:\n",
    "    latest_schema = None\n",
    "    latest_version = 0\n",
    "  def compare_schema(current_schema, latest_schema):\n",
    "    if not latest_schema:\n",
    "      return {\"new_cols\": \"ALL\", \"drop_cols\" : [], \"type_change\" : {}}\n",
    "    current_fields = {f[\"name\"]: f[\"type\"] for f in json.loads(current_schema)[\"fields\"]}\n",
    "    latest_fields = {f[\"name\"] : f[\"type\"] for f in json.loads(latest_schema)[\"fields\"]}\n",
    "\n",
    "    new_cols = set(current_fields) - set(latest_fields)\n",
    "    drop_cols = set(latest_fields) - set(current_fields)\n",
    "    type_change = {c:(latest_fields[c], current_fields[c]) for c in current_fields if c in latest_fields and latest_fields[c] != current_fields[c]}\n",
    "    return {\"new_cols\": list(new_cols), \"drop_cols\": list(drop_cols), \"type_change\": type_change}\n",
    "  schema_diff = compare_schema(current_schema, latest_schema)\n",
    "  print(schema_diff)\n",
    "  if schema_diff[\"new_cols\"] or schema_diff[\"drop_cols\"] or schema_diff[\"type_change\"]:\n",
    "    print(f\"Schema change detected for {source_name}: {schema_diff}\")\n",
    "    new_version = latest_version + 1\n",
    "    df_new_schema = spark.createDataFrame(\n",
    "      [(source_name,new_version,current_schema)],\n",
    "      [\"source\",\"schema_version\",\"schema_json\"]\n",
    "    ).withColumn(\"effective_from\", current_timestamp())\\\n",
    "      .withColumn(\"status\", lit(\"ACTIVE\"))\\\n",
    "      .withColumn(\"schema_version\", col(\"schema_version\").cast(\"int\") )\n",
    "    df_new_schema.write.mode(\"append\").saveAsTable(\"inventory_project.metadata.schema_registry\")\n",
    "    print(f\"✅ Registered new schema version {new_version} for {source_name}\")\n",
    "  else:\n",
    "    print(f\"✅ No schema changes for {source_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cf9ed6d-f9a1-43d5-ae7f-ce31b0a5d32f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fileLookup_df = (\n",
    "    spark.read.table(\"inventory_project.metadata.filelookup\")\n",
    "         .filter((col(\"schema\") == \"bronze\") & (col(\"description\").startswith(\"WMS\")))\n",
    ")\n",
    "fileLookup_df = fileLookup_df.collect()\n",
    "for row in fileLookup_df:\n",
    "  table_name = row['table_name']\n",
    "  try:\n",
    "    print(f\"Started processing {row['table_name']}\")\n",
    "    publish_schema(table_name)\n",
    "  except:\n",
    "    error = str(e)\n",
    "    print(f\"Error processing {row['table_name']}: {e}\")\n",
    "    raise e\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d26e3d05-1477-42f5-bfd4-5da734a109e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from inventory_project.metadata.schema_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27d1af27-94db-4562-acca-9cf1c1d07f3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "source_name = \"wms_inventory_snapshot_raw\"\n",
    "bronze_df = spark.read.table(f\"inventory_project.bronze.{source_name}\")\n",
    "current_schema = bronze_df.schema.json()\n",
    "try:\n",
    "    latest_schema_row = (spark.table(\"inventory_project.metadata.schema_registry\")\n",
    "                              .filter(col(\"source\") == source_name)\n",
    "                              .orderBy(col(\"schema_version\").desc())\n",
    "                              .first())\n",
    "    latest_schema = latest_schema_row['schema_json'] if latest_schema_row else None\n",
    "    latest_version = latest_schema_row['schema_version'] if latest_schema_row else 0\n",
    "except:\n",
    "    latest_schema = None\n",
    "    latest_version = 0\n",
    "\n",
    "print(latest_schema)\n",
    "print(latest_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6ad21d8-cc26-4abf-a7ab-c7255f91e477",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "latest_schema_row = (spark.table(\"inventory_project.metadata.schema_registry\")\n",
    "                              .filter(col(\"source\") == source_name)\n",
    "                              .orderBy(col(\"schema_version\").desc())\n",
    "                              .first())\n",
    "latest_schema = latest_schema_row['schema_json'] if latest_schema_row else None\n",
    "latest_version = latest_schema_row['schema_version'] if latest_schema_row else 0\n",
    "\n",
    "print(latest_schema)\n",
    "print(latest_version)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5590863563574559,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "schema_registry",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
