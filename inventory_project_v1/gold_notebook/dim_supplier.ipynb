{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c91891ee-21a2-4350-9613-acc0353fa192",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Dimension Table for Supplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6657f33-f916-4f13-8ac3-f85bd88bb9ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22dbf606-3d0a-448e-a11f-3487d562cf64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "load_type = 'full'\n",
    "if load_type == 'incremental':\n",
    "  #Get the latest date from the silver table\n",
    "  latest_date = spark.sql(\"select max(ingestion_date) from inventory_project.silver.erp_supplier_silver\").collect()[0][0]\n",
    "  print(latest_date)\n",
    "  source_df = spark.read.table('inventory_project.silver.erp_supplier_silver')\\\n",
    "      .filter(col('ingestion_date') == latest_date)\n",
    "else:\n",
    "  source_df = spark.read.table('inventory_project.silver.erp_supplier_silver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdd97a18-21b3-4c1f-8b19-290c87b03ced",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(source_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5e67d6d-b969-4da3-baaa-b74c4f9e8f82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "source_df = source_df.select(\"supplier_id\",\"supplier_name\",\"lead_days\",\"email\",\"international_coterm\")\n",
    "### Generate surrogate key\n",
    "source_df = source_df.withColumn(\"supplier_key\", concat(lit('supp'),lit('_'),col('supplier_id')))\n",
    "source_df = source_df.withColumn(\"dim_updated_date\", current_date())\n",
    "# Write data to target table\n",
    "if load_type == 'incremental':\n",
    "    target_table = DeltaTable.forName(spark, \"inventory_project.gold.erp_supplier_dim\")\n",
    "    target_table.alias(\"t\")\\\n",
    "        .merge(source_df.alias(\"s\"), \"t.supplier_key = s.supplier_key\")\\\n",
    "        .whenMatchedUpdateAll()\\\n",
    "        .whenNotMatchedInsertAll()\\\n",
    "        .execute()\n",
    "else:\n",
    "    source_df.write.mode(\"overwrite\").saveAsTable(\"inventory_project.gold.erp_supplier_dim\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "dim_supplier",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
